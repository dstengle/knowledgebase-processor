"""Sync command - Upload knowledge base to SPARQL endpoint."""

import click
from pathlib import Path
from typing import Optional
import time

from ..utils import console, print_success, print_error, print_info, print_warning, create_progress, format_duration


@click.command('sync')
@click.argument('endpoint', required=False)
@click.option('--graph', '-g', help='Named graph URI', type=str)
@click.option('--username', '-u', help='Username for authentication', type=str)
@click.option('--password', '-p', help='Password for authentication', 
              type=str, hide_input=True, prompt=False)
@click.option('--dataset', '-d', help='Dataset name', type=str, default='kb')
@click.option('--dry-run', is_flag=True, help='Preview sync without uploading')
@click.option('--force', '-f', is_flag=True, help='Force upload even if data exists')
@click.option('--clear-first', is_flag=True, help='Clear existing data before upload')
@click.option('--batch-size', type=int, default=1000, help='Number of triples per batch')
@click.pass_obj
def sync_cmd(ctx, endpoint, graph, username, password, dataset, dry_run, force, clear_first, batch_size):
    """üîÑ Sync knowledge base to SPARQL endpoint.
    
    Uploads your processed knowledge base to a SPARQL endpoint like Fuseki.
    Supports authentication and various sync strategies.
    
    \b
    Examples:
      kb sync                                    Use configured endpoint
      kb sync http://localhost:3030/kb           Specify endpoint
      kb sync fuseki --dataset kb-test           Use preset with dataset
      kb sync --dry-run                          Preview what would be synced
      kb sync --clear-first                      Replace existing data
    """
    start_time = time.time()
    
    console.print(f"\nüîÑ [heading]Syncing to SPARQL Endpoint[/heading]\n")
    
    # Find knowledge base
    kb_path = Path.cwd()
    kbp_dir = kb_path / ".kbp"
    if not kbp_dir.exists():
        # Look in parent directories
        current = kb_path
        while current != current.parent:
            if (current / ".kbp").exists():
                kbp_dir = current / ".kbp"
                kb_path = current
                break
            current = current.parent
        else:
            print_error("No knowledge base found. Run 'kb init' and 'kb scan' first.")
            return
    
    # Determine endpoint
    if not endpoint:
        # Try to load from config
        endpoint = "http://localhost:3030/kb"  # Default
        print_info("Using default endpoint (configure in .kbp/config.yaml for persistence)")
    elif endpoint == "fuseki":
        endpoint = f"http://localhost:3030/{dataset}"
        print_info(f"Using Fuseki preset with dataset '{dataset}'")
    
    # Determine graph URI
    if not graph:
        graph = "http://example.org/knowledgebase"
        print_info("Using default graph URI")
    
    # Show sync configuration
    console.print(f"  üéØ Endpoint: [cyan]{endpoint}[/cyan]")
    console.print(f"  üìä Graph: [cyan]{graph}[/cyan]")
    console.print(f"  üë§ Authentication: {'Yes' if username else 'No'}")
    console.print(f"  üì¶ Batch size: {batch_size:,} triples")
    
    if dry_run:
        console.print("  üîç [yellow]Dry run mode - no data will be uploaded[/yellow]")
    
    if clear_first:
        print_warning("‚ö†Ô∏è  Clear-first mode - existing data will be removed!")
    
    console.print()
    
    # Get authentication if needed
    if username and not password:
        password = click.prompt("Password", hide_input=True)
    
    # Mock data statistics (in real implementation, would analyze processed data)
    stats = {
        'total_triples': 4567,
        'documents': 156,
        'entities': 1234,
        'todos': 89,
        'relationships': 567
    }
    
    console.print(f"üìã [subheading]Data to sync:[/subheading]")
    console.print(f"  ‚Ä¢ {stats['total_triples']:,} total triples")
    console.print(f"  ‚Ä¢ {stats['documents']:,} documents")
    console.print(f"  ‚Ä¢ {stats['entities']:,} entities") 
    console.print(f"  ‚Ä¢ {stats['todos']:,} todos")
    console.print(f"  ‚Ä¢ {stats['relationships']:,} relationships")
    
    if dry_run:
        elapsed = time.time() - start_time
        console.print(f"\n‚úÖ Dry run completed in {format_duration(elapsed)}")
        console.print("Remove --dry-run to perform actual sync")
        return
    
    # Ask for confirmation if not forcing
    if not force and not ctx.yes:
        if not click.confirm(f"\nProceed with sync to {endpoint}?"):
            console.print("Sync cancelled.")
            return
    
    console.print()
    
    # Simulate sync process
    with create_progress() as progress:
        # Clear existing data if requested
        if clear_first:
            clear_task = progress.add_task("Clearing existing data...", total=1)
            time.sleep(1)  # Simulate clear operation
            progress.advance(clear_task, 1)
        
        # Upload data in batches
        total_batches = (stats['total_triples'] + batch_size - 1) // batch_size
        upload_task = progress.add_task(f"Uploading data in {total_batches} batches...", total=total_batches)
        
        uploaded_triples = 0
        for batch_num in range(total_batches):
            batch_triples = min(batch_size, stats['total_triples'] - uploaded_triples)
            
            # Simulate batch upload
            time.sleep(0.2)  # Simulate network/processing time
            
            uploaded_triples += batch_triples
            progress.advance(upload_task, 1)
        
        # Verify upload
        verify_task = progress.add_task("Verifying upload...", total=1)
        time.sleep(0.5)  # Simulate verification
        progress.advance(verify_task, 1)
    
    elapsed = time.time() - start_time
    print_success(f"Sync completed successfully in {format_duration(elapsed)}")
    
    # Show results
    console.print("\nüìà [subheading]Sync Results:[/subheading]")
    console.print(f"  ‚úÖ {stats['total_triples']:,} triples uploaded")
    console.print(f"  üìä Graph: {graph}")
    console.print(f"  ‚ö° Transfer rate: {stats['total_triples'] / elapsed:.0f} triples/second")
    
    # Provide next steps
    console.print("\nüéØ [subheading]Next Steps:[/subheading]")
    console.print(f"  ‚Ä¢ Test your endpoint: [cyan]{endpoint}[/cyan]")
    console.print("  ‚Ä¢ Run SPARQL queries to explore your data")
    console.print("  ‚Ä¢ Use [cyan]kb status[/cyan] to monitor your knowledge base")
    
    # Show sample queries
    console.print("\nüìù [subheading]Sample SPARQL Queries:[/subheading]")
    console.print("  ‚Ä¢ Count documents:")
    console.print("    [dim]SELECT (COUNT(?doc) as ?count) WHERE { ?doc a <Document> }[/dim]")
    console.print("  ‚Ä¢ List all todos:")
    console.print("    [dim]SELECT ?todo ?label WHERE { ?todo a <TodoItem> ; <label> ?label }[/dim]")